{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11fe74dc",
   "metadata": {},
   "source": [
    "# TAHAP 1 : **Program Untuk Ekstraksi Fitur Data Video**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f35b64",
   "metadata": {},
   "source": [
    "Program berbasis jupyter ini dibuat untuk menjalankan proses ekstraksi fitur data skeletal numerik dari Mediapipe yang diperoleh dari dataset video. \n",
    "- (Note: Simbol x disetiap sub-judul bisa digunakan untuk sub-judul pada laporan).\n",
    "- Untuk menjalankan block program masing-masing, tekan *shift* + *enter* atau klik tombol icon '*Play*' ▶︎.\n",
    "- <b>JALANKAN SETIAP BLOK PROGRAM SECARA SEKUENSIAL!</b>\n",
    "- Konten di dalam program ini bisa digunakan sebagai panduan tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688df834",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d2cc69",
   "metadata": {},
   "source": [
    "## **x.1 Initializations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f6545d",
   "metadata": {},
   "source": [
    "Bagian program pertama yang dijalankan adalah proses inisialisasi. Proses ini berfungsi dengan meng-*import* library yang dibutuhkan dan pengaturan parameter Mediapipe agar program bisa berjalan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5258f973",
   "metadata": {},
   "source": [
    "#### x.1.1 Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff23f23",
   "metadata": {},
   "source": [
    "- Program dimulai dengan meng-*import* *library-library* yang diperlukan.\n",
    "- Lakukan instalasi setiap *library* yang digunakan jika program tidak mendeteksi kode di bawah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f23a66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:34:10.629117Z",
     "start_time": "2025-12-04T09:34:09.992094Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2 as opencv\n",
    "import time\n",
    "import pandas\n",
    "from pathlib import Path\n",
    "\n",
    "import mediapipe\n",
    "from mediapipe.framework.formats import landmark_pb2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08a4487",
   "metadata": {},
   "source": [
    "#### x.1.2 Setup Mediapipe Holistic and drawing utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3725b05",
   "metadata": {},
   "source": [
    "- Setelah selesai proses *import*, program dilanjutkan dengan menjalankan parameter Mediapipe Holistic, Mediapipe Drawing serta parameter pendukung lainnya. \n",
    "- Setiap nilai yang di-set pada parameter tersebut sudah disesuaikan dan menghasilkan output yang optimum, kecuali parameter *model_complexity* (opsional) yang bisa diubah sesuai keinginan.\n",
    "- *model_complexity* berfungsi untuk menentukan daya kualitas deteksi Mediapipe melalui model-model tersedia. Model yang bisa digunakan adalah 0 (*low quality*), 1 (*medium quality*) dan 2 (*high quality*). Semakin tinggi kualitas model yang digunakan, maka daya deteksi semakin akurat (umumnya dengan *less-jitter* saat deteksi *realtime*). Namun, ini juga bisa mempengaruhi performa PC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aa545f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:34:10.653128Z",
     "start_time": "2025-12-04T09:34:10.632120Z"
    }
   },
   "outputs": [],
   "source": [
    "mediapipe_holistic = mediapipe.solutions.holistic\n",
    "mediapipe_drawing = mediapipe.solutions.drawing_utils\n",
    "mediapipe_drawing_styles = mediapipe.solutions.drawing_styles\n",
    "\n",
    "holistic = mediapipe_holistic.Holistic(\n",
    "    static_image_mode=False,\n",
    "    model_complexity=0,\n",
    "    smooth_landmarks=True,\n",
    "    enable_segmentation=False,\n",
    "    refine_face_landmarks=False,\n",
    "    min_detection_confidence=0.25,\n",
    "    min_tracking_confidence=0.25,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531fc4b2",
   "metadata": {},
   "source": [
    "-- Program inisialisasi selesai --"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81985f9",
   "metadata": {},
   "source": [
    "## **x.2 'Children' Utility Functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334530fe",
   "metadata": {},
   "source": [
    "Bagian program kedua adalah kumpulan fungsi-fungsi dan metode-metode program yang diperlukan agar program deteksi bisa berjalan sesuai dengan tahapan proses algoritma yang telah dirancang."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc8174e",
   "metadata": {},
   "source": [
    "#### x.2.1 Distance and landmark normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84def4ed",
   "metadata": {},
   "source": [
    "- Program ini berfungsi menghitung titik tengah antara *landmark* bahu kanan dan bahu kiri, kemudian nilai kedua-dua bahu tersebut dinormalisasikan agar ukurannya tetap statis. Hal ini membantu agar nilai *landmark* tersebut tidak berubah saat *user* dalam posisi dekat atau jauh dari kamera. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2761c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:34:10.659944Z",
     "start_time": "2025-12-04T09:34:10.657133Z"
    }
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(pointA, pointB):\n",
    "    return ((pointA.x - pointB.x) ** 2 + (pointA.y - pointB.y) ** 2) ** 0.5\n",
    "\n",
    "\n",
    "def normalize_landmarks(landmarks, shoulder_center_point, shoulder_width):\n",
    "    if not landmarks or shoulder_width == 0:\n",
    "        return [(0, 0)] * len(landmarks)\n",
    "\n",
    "    return [\n",
    "        (\n",
    "            (landmark_point.x - shoulder_center_point[0]) / shoulder_width,\n",
    "            (landmark_point.y - shoulder_center_point[1]) / shoulder_width\n",
    "        )\n",
    "        for landmark_point in landmarks\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafad345",
   "metadata": {},
   "source": [
    "#### x.2.2 Process single frame using mediapipe holistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d2a89c",
   "metadata": {},
   "source": [
    "- Program ini berfungsi untuk memproses setiap *frame* yang diterima dari *webcam* dan kemudiannya mendeteksi postur tubuh manusia melalui Mediapipe.\n",
    "- Mediapipe meletakkan setiap *landmark* skeletal pada postur tubuh yang dideteksi setiap *frame*-nya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0278871c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:34:10.665947Z",
     "start_time": "2025-12-04T09:34:10.662948Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_frame_with_holistic(frame):\n",
    "    frame_rgb = opencv.cvtColor(frame, opencv.COLOR_BGR2RGB)\n",
    "    frame_rgb.flags.writeable = False\n",
    "    detection_results = holistic.process(frame_rgb)\n",
    "    frame_rgb.flags.writeable = True\n",
    "\n",
    "    output_frame = opencv.cvtColor(frame_rgb, opencv.COLOR_RGB2BGR)\n",
    "    return detection_results, output_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b8c55c",
   "metadata": {},
   "source": [
    "#### x.2.3 Get pose landmarks and shoulder reference points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd8d788",
   "metadata": {},
   "source": [
    "- Program ini berfungsi untuk mengekstrak *landmark* 1 hingga 16 (lengan, bahu dan kepala), kemudian memproses perhitungan mencari nilai titik tengah diantara *landmark* bahu kanan dan kiri (menggunakan program *euclidean_distance* yang telah dibuat sebelumnya), dan kemudian disimpan sebagai output *array* sementara untuk diproses lagi dengan program selanjutnya.\n",
    "- Kumpulan output array yang diperoleh : *pose_landmark_1_to_16*, *shoulder_center_point*, dan *shoulder_width*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68792e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:34:10.672441Z",
     "start_time": "2025-12-04T09:34:10.668112Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_pose_reference_points(detection_results):\n",
    "    if not detection_results.pose_landmarks:\n",
    "        return None, None, None\n",
    "\n",
    "    pose_landmark_1_to_16 = detection_results.pose_landmarks.landmark[:17]\n",
    "\n",
    "    left_shoulder = detection_results.pose_landmarks.landmark[\n",
    "        mediapipe_holistic.PoseLandmark.LEFT_SHOULDER\n",
    "    ]\n",
    "    right_shoulder = detection_results.pose_landmarks.landmark[\n",
    "        mediapipe_holistic.PoseLandmark.RIGHT_SHOULDER\n",
    "    ]\n",
    "\n",
    "    shoulder_center_point = (\n",
    "        (left_shoulder.x + right_shoulder.x) / 2,\n",
    "        (left_shoulder.y + right_shoulder.y) / 2\n",
    "    )\n",
    "\n",
    "    shoulder_width = euclidean_distance(left_shoulder, right_shoulder)\n",
    "\n",
    "    return pose_landmark_1_to_16, shoulder_center_point, shoulder_width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358ea2c5",
   "metadata": {},
   "source": [
    "#### x.2.4 Normalize pose and hands using shoulder-based coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e919524e",
   "metadata": {},
   "source": [
    "- Program ini berfungsi untuk menormalisasikan nilai sebelumnya termasuk *landmark* tangan.\n",
    "- Hasil yang didapatkan berupa nilai *landmark* baru dengan 0 sebagai titik tengah bahu, nilai +1 sebagai titik positif (bagian badan kiri dan bawah) dan nilai -1 sebagai nilai negatif (bagian badan kanan dan atas).\n",
    "- Kumpulan output yang array baru yang diperoleh : *normalized_custom_pose*, *normalized_right_hand* dan *normalized_left_hand*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba0de4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:34:10.677682Z",
     "start_time": "2025-12-04T09:34:10.674445Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_normalized_pose_and_hands(detection_results,\n",
    "                                  pose_landmark_1_to_16,\n",
    "                                  shoulder_center_point,\n",
    "                                  shoulder_width):\n",
    "    normalized_custom_pose = normalize_landmarks(\n",
    "        pose_landmark_1_to_16,\n",
    "        shoulder_center_point,\n",
    "        shoulder_width\n",
    "    )\n",
    "\n",
    "    normalized_right_hand = normalize_landmarks(\n",
    "        detection_results.right_hand_landmarks.landmark,\n",
    "        shoulder_center_point,\n",
    "        shoulder_width\n",
    "    ) if detection_results.right_hand_landmarks else [(0, 0)] * 21\n",
    "\n",
    "    normalized_left_hand = normalize_landmarks(\n",
    "        detection_results.left_hand_landmarks.landmark,\n",
    "        shoulder_center_point,\n",
    "        shoulder_width\n",
    "    ) if detection_results.left_hand_landmarks else [(0, 0)] * 21\n",
    "\n",
    "    return normalized_custom_pose, normalized_right_hand, normalized_left_hand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48596b1c",
   "metadata": {},
   "source": [
    "#### x.2.5 Flatten normalized landmarks into 1D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db78d28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:34:10.682922Z",
     "start_time": "2025-12-04T09:34:10.679685Z"
    }
   },
   "outputs": [],
   "source": [
    "def flatten_normalized_landmarks(normalized_custom_pose,\n",
    "                                 normalized_right_hand,\n",
    "                                 normalized_left_hand):\n",
    "    extracted_frame_landmarks = []\n",
    "\n",
    "    for landmark_x, landmark_y in (\n",
    "        normalized_custom_pose + normalized_right_hand + normalized_left_hand\n",
    "    ):\n",
    "        extracted_frame_landmarks.extend([landmark_x, landmark_y])\n",
    "\n",
    "    return extracted_frame_landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab7f89d",
   "metadata": {},
   "source": [
    "#### x.2.6 Drawing pose + hands on frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc12255",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:34:10.689925Z",
     "start_time": "2025-12-04T09:34:10.685925Z"
    }
   },
   "outputs": [],
   "source": [
    "def draw_pose_and_hands_on_frame(output_frame, detection_results):\n",
    "\n",
    "    # Filter pose landmarks to 0–16 (upper body)\n",
    "    filtered_pose = landmark_pb2.NormalizedLandmarkList(\n",
    "        landmark=[detection_results.pose_landmarks.landmark[i] for i in range(17)]\n",
    "    )\n",
    "\n",
    "    filtered_connections = [\n",
    "        connection\n",
    "        for connection in mediapipe_holistic.POSE_CONNECTIONS\n",
    "        if connection[0] < 17 and connection[1] < 17\n",
    "    ]\n",
    "\n",
    "    # Draw pose\n",
    "    mediapipe_drawing.draw_landmarks(\n",
    "        output_frame,\n",
    "        filtered_pose,\n",
    "        filtered_connections,\n",
    "        landmark_drawing_spec=mediapipe_drawing_styles.get_default_pose_landmarks_style()\n",
    "    )\n",
    "\n",
    "    # Draw right hand\n",
    "    if detection_results.right_hand_landmarks:\n",
    "        mediapipe_drawing.draw_landmarks(\n",
    "            output_frame,\n",
    "            detection_results.right_hand_landmarks,\n",
    "            mediapipe_holistic.HAND_CONNECTIONS,\n",
    "            landmark_drawing_spec=mediapipe_drawing_styles.get_default_hand_landmarks_style()\n",
    "        )\n",
    "\n",
    "    # Draw left hand\n",
    "    if detection_results.left_hand_landmarks:\n",
    "        mediapipe_drawing.draw_landmarks(\n",
    "            output_frame,\n",
    "            detection_results.left_hand_landmarks,\n",
    "            mediapipe_holistic.HAND_CONNECTIONS,\n",
    "            landmark_drawing_spec=mediapipe_drawing_styles.get_default_hand_landmarks_style()\n",
    "        )\n",
    "\n",
    "    return output_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a568ad6a",
   "metadata": {},
   "source": [
    "#### x.2.7 Draw normalized landmarks on a blank canvas (stickman view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14f4650",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:34:10.730091Z",
     "start_time": "2025-12-04T09:34:10.692053Z"
    }
   },
   "outputs": [],
   "source": [
    "def draw_normalized_stickman(normalized_custom_pose,\n",
    "                             normalized_right_hand,\n",
    "                             normalized_left_hand,\n",
    "                             canvas_size=(500, 500),\n",
    "                             scale=145,\n",
    "\n",
    "                             # axes / grid / ticks\n",
    "                             show_center_cross=True,\n",
    "                             show_grid=True,\n",
    "                             grid_interval=0.5,     # in normalized units\n",
    "                             show_ticks=True,\n",
    "                             tick_interval=0.5,     # in normalized units\n",
    "                             tick_size_pixels=5,\n",
    "\n",
    "                             # pose colors\n",
    "                             pose_dot_color=(255, 255, 255),\n",
    "                             pose_line_color=(255, 255, 255),\n",
    "                             pose_text_color=(255, 255, 255),\n",
    "\n",
    "                             # right hand colors (dots/lines)\n",
    "                             right_dot_color=(200, 200, 200),\n",
    "                             right_line_color=(200, 200, 200),\n",
    "\n",
    "                             # left hand colors (dots/lines)\n",
    "                             left_dot_color=(200, 200, 200),\n",
    "                             left_line_color=(200, 200, 200),\n",
    "\n",
    "                             # hand label colors (near dots + bottom lists)\n",
    "                             right_label_color=(0, 255, 0),      # green\n",
    "                             left_label_color=(0, 165, 255),     # orange-ish\n",
    "\n",
    "                             # overlay info\n",
    "                             sequence_count=None,\n",
    "                             frame_index=None,\n",
    "                             label=None,\n",
    "                             fps=None,\n",
    "                             overlay_color=(0, 255, 0),\n",
    "                             overlay_font_scale=0.6,\n",
    "\n",
    "                             # pose text controls\n",
    "                             show_pose_coords=True,\n",
    "                             show_pose_numbers=True,\n",
    "\n",
    "                             # hand list controls (bottom)\n",
    "                             show_hand_lists=True,\n",
    "                             hand_font_scale=0.25,\n",
    "\n",
    "                             # hand labels near dots\n",
    "                             show_hand_labels=True,\n",
    "                             hand_label_font_scale=0.25):\n",
    "    \"\"\"\n",
    "    Stickman visualization with:\n",
    "      - Pose dots + P{i} labels + coords near pose points\n",
    "      - Hand dots + RH_i/LH_i labels near hand points (separate colors)\n",
    "      - Bottom-left RH_i (x,y), bottom-right (x,y) LH_i (skip zero points)\n",
    "      - Overlay: label, sequence, frame, FPS\n",
    "      - Axes: X red horizontal, Y green vertical\n",
    "      - Tick marks and optional faint grid in normalized space\n",
    "    \"\"\"\n",
    "\n",
    "    h, w = canvas_size\n",
    "    stickman_frame = opencv.UMat(h, w, opencv.CV_8UC3).get()\n",
    "    stickman_frame[:] = 0\n",
    "\n",
    "    center_x, center_y = w // 2, h // 2\n",
    "\n",
    "    # ---- overlay info block (top-left) ----\n",
    "    overlay_lines = []\n",
    "    if label is not None:\n",
    "        overlay_lines.append(f\"Label: {label}\")\n",
    "    if sequence_count is not None and frame_index is not None:\n",
    "        overlay_lines.append(f\"Seq: {sequence_count:03} | Frame: {frame_index:03}\")\n",
    "    elif sequence_count is not None:\n",
    "        overlay_lines.append(f\"Seq: {sequence_count:03}\")\n",
    "    elif frame_index is not None:\n",
    "        overlay_lines.append(f\"Frame: {frame_index:03}\")\n",
    "    if fps is not None:\n",
    "        overlay_lines.append(f\"FPS: {fps:.1f}\")\n",
    "\n",
    "    for i, text in enumerate(overlay_lines):\n",
    "        opencv.putText(\n",
    "            stickman_frame,\n",
    "            text,\n",
    "            (10, 25 + i * 22),\n",
    "            opencv.FONT_HERSHEY_SIMPLEX,\n",
    "            overlay_font_scale,\n",
    "            overlay_color,\n",
    "            2,\n",
    "            opencv.LINE_AA\n",
    "        )\n",
    "\n",
    "    # ---- axes / grid / ticks at (0,0) ----\n",
    "    if show_center_cross:\n",
    "        x_color = (0, 0, 255)     # red (horizontal axis)\n",
    "        y_color = (0, 255, 0)     # green (vertical axis)\n",
    "        grid_color = (60, 60, 60) # faint dark gray grid\n",
    "\n",
    "        # convert normalized interval -> pixels, clamp to >= 1px\n",
    "        grid_step_px = max(1, int(scale * grid_interval)) if grid_interval else None\n",
    "        tick_step_px = max(1, int(scale * tick_interval)) if tick_interval else None\n",
    "\n",
    "        # ---- faint grid (optional) ----\n",
    "        if show_grid and grid_step_px is not None:\n",
    "            # vertical lines\n",
    "            x = center_x\n",
    "            while x < w:\n",
    "                opencv.line(stickman_frame, (x, 0), (x, h), grid_color, 1)\n",
    "                x += grid_step_px\n",
    "            x = center_x\n",
    "            while x > 0:\n",
    "                opencv.line(stickman_frame, (x, 0), (x, h), grid_color, 1)\n",
    "                x -= grid_step_px\n",
    "\n",
    "            # horizontal lines\n",
    "            y = center_y\n",
    "            while y < h:\n",
    "                opencv.line(stickman_frame, (0, y), (w, y), grid_color, 1)\n",
    "                y += grid_step_px\n",
    "            y = center_y\n",
    "            while y > 0:\n",
    "                opencv.line(stickman_frame, (0, y), (w, y), grid_color, 1)\n",
    "                y -= grid_step_px\n",
    "\n",
    "        # ---- main axes ----\n",
    "        opencv.line(stickman_frame, (0, center_y), (w, center_y), x_color, 1)  # X axis\n",
    "        opencv.line(stickman_frame, (center_x, 0), (center_x, h), y_color, 1)  # Y axis\n",
    "\n",
    "        # ---- tick marks (optional) ----\n",
    "        if show_ticks and tick_step_px is not None:\n",
    "            t = tick_size_pixels\n",
    "\n",
    "            # X-axis ticks\n",
    "            x = center_x\n",
    "            while x < w:\n",
    "                opencv.line(stickman_frame, (x, center_y - t), (x, center_y + t), x_color, 2)\n",
    "                x += tick_step_px\n",
    "            x = center_x\n",
    "            while x > 0:\n",
    "                opencv.line(stickman_frame, (x, center_y - t), (x, center_y + t), x_color, 2)\n",
    "                x -= tick_step_px\n",
    "\n",
    "            # Y-axis ticks\n",
    "            y = center_y\n",
    "            while y < h:\n",
    "                opencv.line(stickman_frame, (center_x - t, y), (center_x + t, y), y_color, 2)\n",
    "                y += tick_step_px\n",
    "            y = center_y\n",
    "            while y > 0:\n",
    "                opencv.line(stickman_frame, (center_x - t, y), (center_x + t, y), y_color, 2)\n",
    "                y -= tick_step_px\n",
    "\n",
    "        # ---- axis labels ----\n",
    "        axis_font_scale = 0.4\n",
    "        axis_thickness = 1\n",
    "\n",
    "        # X labels\n",
    "        opencv.putText(stickman_frame, \"-X\", (10, center_y - 5),\n",
    "                       opencv.FONT_HERSHEY_SIMPLEX, axis_font_scale, x_color, axis_thickness, opencv.LINE_AA)\n",
    "        opencv.putText(stickman_frame, \"+X\", (w - 40, center_y - 5),\n",
    "                       opencv.FONT_HERSHEY_SIMPLEX, axis_font_scale, x_color, axis_thickness, opencv.LINE_AA)\n",
    "\n",
    "        # Y labels (up is -Y, down is +Y)\n",
    "        opencv.putText(stickman_frame, \"-Y\", (center_x + 5, 20),\n",
    "                       opencv.FONT_HERSHEY_SIMPLEX, axis_font_scale, y_color, axis_thickness, opencv.LINE_AA)\n",
    "        opencv.putText(stickman_frame, \"+Y\", (center_x + 5, h - 10),\n",
    "                       opencv.FONT_HERSHEY_SIMPLEX, axis_font_scale, y_color, axis_thickness, opencv.LINE_AA)\n",
    "\n",
    "        # center label\n",
    "        opencv.putText(stickman_frame, \"(0,0)\",\n",
    "                       (center_x + 6, center_y - 6),\n",
    "                       opencv.FONT_HERSHEY_SIMPLEX,\n",
    "                       0.45, (255, 255, 255), 1, opencv.LINE_AA)\n",
    "\n",
    "    # mapping normalized -> pixel\n",
    "    def to_pixel(pt):\n",
    "        x, y = pt\n",
    "        return int(center_x + x * scale), int(center_y + y * scale)\n",
    "\n",
    "    # ---- pose text near dots ----\n",
    "    def draw_pose_text(px, py, idx, x_norm, y_norm):\n",
    "        lines = []\n",
    "        if show_pose_numbers:\n",
    "            lines.append(f\"P{idx}\")\n",
    "        if show_pose_coords:\n",
    "            lines.append(f\"({x_norm:.2f},{y_norm:.2f})\")\n",
    "\n",
    "        for j, text in enumerate(lines):\n",
    "            opencv.putText(\n",
    "                stickman_frame,\n",
    "                text,\n",
    "                (px + 4, py + 4 + j * 12),\n",
    "                opencv.FONT_HERSHEY_SIMPLEX,\n",
    "                0.35,\n",
    "                pose_text_color,\n",
    "                1,\n",
    "                opencv.LINE_AA\n",
    "            )\n",
    "\n",
    "    # ---- hand label near dots ----\n",
    "    def draw_hand_label(px, py, text, color):\n",
    "        opencv.putText(\n",
    "            stickman_frame,\n",
    "            text,\n",
    "            (px + 3, py + 3),\n",
    "            opencv.FONT_HERSHEY_SIMPLEX,\n",
    "            hand_label_font_scale,\n",
    "            color,\n",
    "            1,\n",
    "            opencv.LINE_AA\n",
    "        )\n",
    "\n",
    "    # ---------------- POSE ----------------\n",
    "    pose_pixels = [to_pixel(pt) for pt in normalized_custom_pose]\n",
    "\n",
    "    for i, (px, py) in enumerate(pose_pixels):\n",
    "        x_norm, y_norm = normalized_custom_pose[i]\n",
    "        opencv.circle(stickman_frame, (px, py), 3, pose_dot_color, -1)\n",
    "        draw_pose_text(px, py, i, x_norm, y_norm)\n",
    "\n",
    "    for a, b in mediapipe_holistic.POSE_CONNECTIONS:\n",
    "        if a < 17 and b < 17:\n",
    "            opencv.line(stickman_frame, pose_pixels[a], pose_pixels[b], pose_line_color, 2)\n",
    "\n",
    "    # ---------------- RIGHT HAND (dots + labels) ----------------\n",
    "    right_pixels = [to_pixel(pt) for pt in normalized_right_hand]\n",
    "\n",
    "    for i, (px, py) in enumerate(right_pixels):\n",
    "        opencv.circle(stickman_frame, (px, py), 2, right_dot_color, -1)\n",
    "        if show_hand_labels:\n",
    "            draw_hand_label(px, py, f\"RH_{i}\", right_label_color)\n",
    "\n",
    "    for a, b in mediapipe_holistic.HAND_CONNECTIONS:\n",
    "        opencv.line(stickman_frame, right_pixels[a], right_pixels[b], right_line_color, 1)\n",
    "\n",
    "    # ---------------- LEFT HAND (dots + labels) ----------------\n",
    "    left_pixels = [to_pixel(pt) for pt in normalized_left_hand]\n",
    "\n",
    "    for i, (px, py) in enumerate(left_pixels):\n",
    "        opencv.circle(stickman_frame, (px, py), 2, left_dot_color, -1)\n",
    "        if show_hand_labels:\n",
    "            draw_hand_label(px, py, f\"LH_{i}\", left_label_color)\n",
    "\n",
    "    for a, b in mediapipe_holistic.HAND_CONNECTIONS:\n",
    "        opencv.line(stickman_frame, left_pixels[a], left_pixels[b], left_line_color, 1)\n",
    "\n",
    "    # ---------------- BOTTOM HAND LISTS (skip (0,0)) ----------------\n",
    "    if show_hand_lists:\n",
    "        epsilon = 1e-6\n",
    "        bottom_margin = 10\n",
    "        line_height = 12\n",
    "        start_y = h - bottom_margin - (21 * line_height)\n",
    "\n",
    "        # Right-hand list bottom-left\n",
    "        x_left = 10\n",
    "        right_line_index = 0\n",
    "        for i in range(21):\n",
    "            x_norm, y_norm = normalized_right_hand[i]\n",
    "            if abs(x_norm) < epsilon and abs(y_norm) < epsilon:\n",
    "                continue\n",
    "\n",
    "            text = f\"RH_{i} ({x_norm:.2f},{y_norm:.2f})\"\n",
    "            y_pos = start_y + right_line_index * line_height\n",
    "            right_line_index += 1\n",
    "\n",
    "            opencv.putText(\n",
    "                stickman_frame,\n",
    "                text,\n",
    "                (x_left, y_pos),\n",
    "                opencv.FONT_HERSHEY_SIMPLEX,\n",
    "                hand_font_scale,\n",
    "                right_label_color,\n",
    "                1,\n",
    "                opencv.LINE_AA\n",
    "            )\n",
    "\n",
    "        # Left-hand list bottom-right (right aligned)\n",
    "        x_right = w - 10\n",
    "        left_line_index = 0\n",
    "        for i in range(21):\n",
    "            x_norm, y_norm = normalized_left_hand[i]\n",
    "            if abs(x_norm) < epsilon and abs(y_norm) < epsilon:\n",
    "                continue\n",
    "\n",
    "            text = f\"({x_norm:.2f},{y_norm:.2f}) LH_{i}\"\n",
    "            y_pos = start_y + left_line_index * line_height\n",
    "            left_line_index += 1\n",
    "\n",
    "            (text_w, _), _ = opencv.getTextSize(\n",
    "                text, opencv.FONT_HERSHEY_SIMPLEX, hand_font_scale, 1\n",
    "            )\n",
    "            opencv.putText(\n",
    "                stickman_frame,\n",
    "                text,\n",
    "                (x_right - text_w, y_pos),\n",
    "                opencv.FONT_HERSHEY_SIMPLEX,\n",
    "                hand_font_scale,\n",
    "                left_label_color,\n",
    "                1,\n",
    "                opencv.LINE_AA\n",
    "            )\n",
    "\n",
    "    return stickman_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d55cd4c",
   "metadata": {},
   "source": [
    "## **3. 'Parent' Utility Functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070dd92b",
   "metadata": {},
   "source": [
    "#### 3.1 Extract features + visualizations from one frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9daac1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:34:10.736094Z",
     "start_time": "2025-12-04T09:34:10.732094Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_landmarks_from_frame(frame, video_path,\n",
    "                                 sequence_count=None,\n",
    "                                 frame_index=None,\n",
    "                                 label=None,\n",
    "                                 fps=None):\n",
    "    detection_results, output_frame = process_frame_with_holistic(frame)\n",
    "\n",
    "    pose_landmark_1_to_16, shoulder_center_point, shoulder_width = \\\n",
    "        get_pose_reference_points(detection_results)\n",
    "\n",
    "    if pose_landmark_1_to_16 is None:\n",
    "        return None, output_frame, None\n",
    "\n",
    "    normalized_custom_pose, normalized_right_hand, normalized_left_hand = \\\n",
    "        get_normalized_pose_and_hands(\n",
    "            detection_results,\n",
    "            pose_landmark_1_to_16,\n",
    "            shoulder_center_point,\n",
    "            shoulder_width\n",
    "        )\n",
    "\n",
    "    extracted_frame_landmarks = flatten_normalized_landmarks(\n",
    "        normalized_custom_pose,\n",
    "        normalized_right_hand,\n",
    "        normalized_left_hand\n",
    "    )\n",
    "    \n",
    "    output_frame = draw_pose_and_hands_on_frame(output_frame, detection_results)\n",
    "\n",
    "    opencv.putText(\n",
    "        output_frame,\n",
    "        f'Name : {video_path}',\n",
    "        (10, 30),\n",
    "        opencv.FONT_HERSHEY_SIMPLEX,\n",
    "        0.75,\n",
    "        (255, 255, 255),\n",
    "        2,\n",
    "        opencv.LINE_AA,\n",
    "    )\n",
    "\n",
    "    # Stickman with overlays\n",
    "    stickman_frame = draw_normalized_stickman(\n",
    "        normalized_custom_pose,\n",
    "        normalized_right_hand,\n",
    "        normalized_left_hand,\n",
    "        sequence_count=sequence_count,\n",
    "        frame_index=frame_index,\n",
    "        label=label,\n",
    "        fps=fps\n",
    "    )\n",
    "\n",
    "    return extracted_frame_landmarks, output_frame, stickman_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec5e669",
   "metadata": {},
   "source": [
    "#### 3.2 Extract sequence from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c54872a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:34:10.741504Z",
     "start_time": "2025-12-04T09:34:10.738221Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_sequence_from_video(video_path, label, sequence_count):\n",
    "    video_file = opencv.VideoCapture(str(video_path))\n",
    "    sequence = []\n",
    "\n",
    "    prev_time = time.time()\n",
    "    fps = 0.0\n",
    "    frame_index = 0\n",
    "\n",
    "    while True:\n",
    "        available, frame = video_file.read()\n",
    "        if not available:\n",
    "            break\n",
    "\n",
    "        # FPS calculation\n",
    "        current_time = time.time()\n",
    "        dt = current_time - prev_time\n",
    "        prev_time = current_time\n",
    "        if dt > 0:\n",
    "            fps = 1.0 / dt\n",
    "\n",
    "        frame_data, output_frame, stickman_frame = extract_landmarks_from_frame(\n",
    "            frame, video_path,\n",
    "            sequence_count=sequence_count,\n",
    "            frame_index=frame_index,\n",
    "            label=label,\n",
    "            fps=fps\n",
    "        )\n",
    "\n",
    "        frame_index += 1\n",
    "\n",
    "        if frame_data is not None:\n",
    "            sequence.append(frame_data)\n",
    "\n",
    "            opencv.imshow(\"Original Mediapipe Holistic\", output_frame)\n",
    "            if stickman_frame is not None:\n",
    "                opencv.imshow(\"Normalized Stickman View\", stickman_frame)\n",
    "\n",
    "            if opencv.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    video_file.release()\n",
    "    opencv.destroyAllWindows()\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e81765",
   "metadata": {},
   "source": [
    "#### 3.3 Generate CSV headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca85907f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:34:10.746645Z",
     "start_time": "2025-12-04T09:34:10.743507Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_csv_headers():\n",
    "    headers = []\n",
    "\n",
    "    # Pose: 17 points\n",
    "    for i in range(17):\n",
    "        headers.append(f\"P{i}_x\")\n",
    "        headers.append(f\"P{i}_y\")\n",
    "\n",
    "    # Right hand: 21 points\n",
    "    for i in range(21):\n",
    "        headers.append(f\"RH{i}_x\")\n",
    "        headers.append(f\"RH{i}_y\")\n",
    "\n",
    "    # Left hand: 21 points\n",
    "    for i in range(21):\n",
    "        headers.append(f\"LH{i}_x\")\n",
    "        headers.append(f\"LH{i}_y\")\n",
    "\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b46270d",
   "metadata": {},
   "source": [
    "#### 3.4 Save sequence to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f23b5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:34:10.751650Z",
     "start_time": "2025-12-04T09:34:10.748648Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_sequence_to_csv(sequence, label, sequence_count, output_folder):\n",
    "    headers = generate_csv_headers()\n",
    "    data_frame = pandas.DataFrame(sequence, columns=headers)\n",
    "\n",
    "    output_file = output_folder / f\"{label}_{sequence_count:03}.csv\"\n",
    "    data_frame.to_csv(output_file, index=False, header=True)\n",
    "\n",
    "    print(f\"[SUCCESS] Saved : {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7052d91",
   "metadata": {},
   "source": [
    "# **x.4 Main function**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247dfddb",
   "metadata": {},
   "source": [
    "#### x.4.1 Folder input configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7ce9c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:34:10.883378Z",
     "start_time": "2025-12-04T09:34:10.755772Z"
    }
   },
   "outputs": [],
   "source": [
    "input_folder = Path(\"_videos/\")\n",
    "output_folder = Path(\"_csv/\")\n",
    "output_folder.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba612c09",
   "metadata": {},
   "source": [
    "#### x.4.2 Run sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575bd02d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-12-04T09:34:10.887382Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "total_videos = 0\n",
    "total_saved = 0\n",
    "total_skipped = 0\n",
    "total_frames_kept = 0\n",
    "\n",
    "for label_folder in input_folder.iterdir():\n",
    "    if not label_folder.is_dir():\n",
    "        continue\n",
    "\n",
    "    label = label_folder.name\n",
    "    video_list = list(label_folder.glob(\"*.mp4\"))\n",
    "    total_in_class = len(video_list)\n",
    "\n",
    "    SEQUENCE_COUNT = 0\n",
    "\n",
    "    for idx, video_path in enumerate(video_list, start=1):\n",
    "        total_videos += 1\n",
    "\n",
    "        sequence = extract_sequence_from_video(video_path, label, SEQUENCE_COUNT)\n",
    "\n",
    "        if not sequence:\n",
    "            total_skipped += 1\n",
    "            continue\n",
    "\n",
    "        save_sequence_to_csv(sequence, label, SEQUENCE_COUNT, output_folder)\n",
    "\n",
    "        total_saved += 1\n",
    "        total_frames_kept += len(sequence)\n",
    "\n",
    "        SEQUENCE_COUNT += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SIBIFullEdition312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
